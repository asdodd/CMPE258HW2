{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dodd_Alex_CMPE258_HW_Q2.ipynb","provenance":[],"authorship_tag":"ABX9TyNuJ9MG3knOgUZZ5dMLPnqn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"47ls3eD3xeWw"},"source":["2. For an object detection problem, assume you are designing a YOLO like model to do the job. Your input image size is 127 x 127 (RGB). We are looking for a 8x8 output grid size. The number of classes is 20 and for each cell in the 8x8 grid, we are considering 2 anchors. Design the CNN network and as a designer feel free to set your networks hyperparameters as you wish. "]},{"cell_type":"markdown","metadata":{"id":"FEi0JWWoD5l_"},"source":["Load Modules"]},{"cell_type":"code","metadata":{"id":"o3xe0aZwxYNk"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Dense\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","from tensorflow.keras.utils import to_categorical\n","\n","from sklearn.datasets import make_blobs\n","from sklearn.model_selection import train_test_split\n","\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"72w5yHcvD9cc"},"source":["Write function to build CNN with FCs"]},{"cell_type":"code","metadata":{"id":"tFm0SpuJzLux"},"source":["def build(width=127,height=127,depth = 3,classes=20):\n","  # initialize the model along with the input shape to be\n","  # \"channels last\" and the channels dimension itself\n","  model = Sequential()\n","  inputShape = (height, width, depth)\n","  chanDim = -1\n","\n","  # CONV => RELU => BN => POOL\n","  model.add(Conv2D(8, (5, 5), padding=\"same\",\n","    input_shape=inputShape))\n","  model.add(Activation(\"relu\"))\n","  model.add(BatchNormalization(axis=chanDim))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  # first set of (CONV => RELU => CONV => RELU) * 2 => POOL\n","  model.add(Conv2D(16, (3, 3), padding=\"same\"))\n","  model.add(Activation(\"relu\"))\n","  model.add(BatchNormalization(axis=chanDim))\n","  model.add(Conv2D(16, (3, 3), padding=\"same\"))\n","  model.add(Activation(\"relu\"))\n","  model.add(BatchNormalization(axis=chanDim))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  # second set of (CONV => RELU => CONV => RELU) * 2 => POOL\n","  model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","  model.add(Activation(\"relu\"))\n","  model.add(BatchNormalization(axis=chanDim))\n","  model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","  model.add(Activation(\"relu\"))\n","  model.add(BatchNormalization(axis=chanDim))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  # First FC Layer\n","  model.add(Flatten())\n","  model.add(Activation(\"relu\"))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5)) #Regularization\n","\n","  # Second FC Layer\n","  model.add(Flatten())\n","  model.add(Activation(\"relu\"))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5)) #Regularization\n","\n","  # Third FC Layer\n","  model.add(Dense(classes))\n","  model.add(Activation(\"softmax\"))\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rtJYQ0CDEDBW"},"source":["Write code to extract all possible bounding boxes with object score (likelihood the box contains an object) and class probability (likelihood of which class it is)"]},{"cell_type":"code","metadata":{"id":"npXJXn6b20Ha"},"source":["def extractInfo(modelOutput, anchors, numClass):\n","    featureDim = modelOutput.shape\n","    numAnchor = anchors.shape[0]  # get the number of anchors, 5 for the Pascal dataset\n","    modelOutput = tf.reshape(modelOutput, shape=(-1, featureDim[1], featureDim[2], numAnchor, numClass + 5))\n","\n","    imageShape = featureDim[1:3]  # get the width and height of output feature map\n","\n","    boxXY = tf.nn.sigmoid(modelOutput[..., :2])  # boxXY now w.r.t top left corner of its grid(on grid scale)\n","\n","    idx = getOffset(imageShape) # convert box center to grid scale\n","    idx = tf.cast(idx, modelOutput.dtype)\n","    anchors = tf.cast(tf.reshape(anchors, (1, 1, 1, numAnchor, 2)), idx.dtype)\n","    boxXY = (boxXY + idx)  \n","\n","    boxWH = tf.math.exp(modelOutput[..., 2:4]) \n","\n","    boxWH = boxWH * anchors\n","\n","    objScore = tf.nn.sigmoid(modelOutput[..., 4:5])  # objectiveness score; must be between 0 and 1\n","    classProb = tf.nn.softmax(modelOutput[..., 5:])  # probability of classes; pass through a softmax gate to obtain prob.\n","    \n","    return boxXY, boxWH, objScore, classProb\n","\n","\n","def getOffset(shape):\n","    hIndex = tf.reshape(tf.range(start=0, limit=shape[0]), (shape[0], 1))\n","    hIndex = tf.tile(hIndex, [1, shape[1]])  # expand in the height direction\n","    wIndex = tf.reshape(tf.range(start=0, limit=shape[1]), (1, shape[1]))\n","    wIndex = tf.tile(wIndex, [shape[0], 1])  # expand in the width direction\n","    idx = tf.stack([wIndex, hIndex], axis=-1)\n","    idx = tf.reshape(idx, shape=(1, *shape, 1, 2)) # reshape the offset so that it can add to boxXY directly\n","    return idx"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q2F_kkNIEX_b"},"source":["Get the box location and scale it from the grid size to the original image size "]},{"cell_type":"code","metadata":{"id":"VgO0VFyo24jw"},"source":["def getBoxLoc(boxXY, boxWH):\n","    topLeft = boxXY - boxWH / 2  # top left\n","    bottomRight = boxXY + boxWH / 2  # bottom right\n","    # the last dimension is (x1, y1, x2, y2)\n","    # top left means it is closer to (0,0) in the image, which is the top-left corner\n","    # if displayed by matplotlib \n","    return tf.concat([topLeft, bottomRight], axis=-1)\n","\n","def scaleBox(boxLoc, scale=(32, 32)):\n","    height, width = scale[0], scale[1]\n","    shape = tf.stack([height, width, height, width])\n","    shape = tf.reshape(shape, [1, 4])\n","    shape = tf.cast(shape, boxLoc.dtype)\n","    return boxLoc * shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I_f_c5MpEewy"},"source":["Filter out boxes with low object scores (unlikely to have objects in them) \n","\n","Filter out boxes that greatly overlap and only return the box that has the highest object score"]},{"cell_type":"code","metadata":{"id":"VOXVbAjf269e"},"source":["def filterBox(boxLoc, objScore, classProb, scoreThresh=0.5):\n","    boxScore = objScore * classProb  # (None, B1, B2, S, NCLASS)\n","    boxClass = tf.argmax(boxScore, axis=-1)  # shape = (None, S, S, B)\n","    boxScore = tf.math.reduce_max(boxScore, axis=-1)  # shape = (None, S, S, B)\n","    mask = boxScore >= scoreThresh\n","    # filter out low-confidence boxes\n","    boxes = tf.boolean_mask(boxLoc, mask)\n","    scores = tf.boolean_mask(boxScore, mask)\n","    classes = tf.boolean_mask(boxClass, mask)\n","\n","    return boxes, scores, classes\n","\n","\n","\n","def nonMaxSuppress(boxLoc, score, classPredict, maxBox=20, iouThresh=0.5):\n","    idx = tf.image.non_max_suppression(boxLoc, score, maxBox, iou_threshold=iouThresh)\n","    boxLoc = tf.gather(boxLoc, idx)\n","    score = tf.gather(score, idx)\n","    classPredict = tf.gather(classPredict, idx)\n","    return boxLoc, score, classPredict"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NwT4YyrfEtMT"},"source":["Load data (no data in the assignment)"]},{"cell_type":"code","metadata":{"id":"t4qmG43Y4iwJ"},"source":["# Load data (no data given for assignment)\n","randomImages = np.random.randn(100,127,127,3)\n","randomLabels = np.random.randint(1,5,size=100)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t8mUgeGCEwFN"},"source":["Set up the CNN and fit the model"]},{"cell_type":"code","metadata":{"id":"u2kOevGo5ZGH"},"source":["# Set epochs to 10 and learning rate to 0.001\n","epochs = 10\n","learningRate = 1e-3\n","\n","# Use the Adam learning rate optimizer\n","opt = Adam(lr=learningRate, decay=learningRate / (epochs * 0.5))\n","\n","# Build and compile the model\n","model = build()\n","model.compile(loss=\"category_crossentropy\", optimizer=opt,\n","\tmetrics=[\"accuracy\"])\n","\n","# HotEncode Labels\n","numLabels = len(np.unique(randomLabels))\n","randomLabels = to_categorical(randomLabels, numLabels)\n","\n","\n","# Fit the model\n","H = model.fit(x = randomImages, \n","              y =randomLabels,\n","              batch_size=10,\n","              epochs=epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BKJDlkLUEz0B"},"source":["take the output predictions and feed them into the functions listed above\n","1. get all bounding boxes\n","2. find where each bounding box is on the image\n","3. filter out boxes with low object score\n","4. filter out boxes with large overlap\n","5. plot boxes on image (not seen here since there are no input images)"]},{"cell_type":"code","metadata":{"id":"djynZl13Aazi"},"source":["modelOutput = model.predict(randomImage)\n","bXY, bWH, objScore, classProb = extractInfo(modelOutput,anchors=2,numClass=20)\n","bLoc = getBoxLoc(bXY,bWH)\n","bLocScale = scaleBox(bLoc,(127/8,127/8)) #Image sized divided by number of grids\n","boxes, scores, classes = filterBox(bLocScale, objScore, classProb, scoreThresh=0.5):\n","boxLoc, score, classPredict = nonMaxSuppress(bLoc, scores, classProb, maxBox=20, iouThresh=0.5):\n"],"execution_count":null,"outputs":[]}]}